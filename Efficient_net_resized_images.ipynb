{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import libs\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.applications\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "\n",
    "from efficientnet.keras import EfficientNetB0\n",
    "from efficientnet.keras import center_crop_and_resize, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Loading all pictures of a folder and returns them as 3D arrays in a list. Additionally returns the filenames as a seperate list\n",
    "def load_images(path):\n",
    "    image_list = []\n",
    "    filename_list = []\n",
    "    for filename in os.listdir(path):\n",
    "        img = cv2.imread(os.path.join(path,filename))\n",
    "        name = filename\n",
    "        if img is not None:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            image_list.append(img)\n",
    "            filename_list.append(name)\n",
    "    return image_list, filename_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepro(img_list):\n",
    "    prepro_list=[]\n",
    "    dim = (331, 331)\n",
    "    for i in range(len(img_list)):\n",
    "        #curr = cv2.resize(img_list[i], dim)\n",
    "        image_size = model.input_shape[1]\n",
    "        x = center_crop_and_resize(img_list[i], image_size=image_size)\n",
    "        x = preprocess_input(x)\n",
    "        x = np.expand_dims(x, 0)\n",
    "        \n",
    "        prepro_list.append(x)\n",
    "    return prepro_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(path):\n",
    "    image_list, name_list = load_images(path)\n",
    "    processed_img = prepro(image_list)\n",
    "    results = []\n",
    "    for i in range(len(processed_img)):\n",
    "        y = model.predict(processed_img[i])\n",
    "        pred=decode_predictions(y)\n",
    "        results.append(pred)\n",
    "    return name_list, results\n",
    "def write_df (name_list, results):\n",
    "    pre_1_nas, pre_1_name, pre_1_prob, pre_2_nas, pre_2_name, pre_2_prob, pre_3_nas, pre_3_name, pre_3_prob, pre_4_nas, pre_4_name, pre_4_prob, pre_5_nas, pre_5_name, pre_5_prob = ([] for i in range(15))\n",
    "    for i in range(0, len(results)):    \n",
    "        pre_1_nas.append(results[i][0][0][0])\n",
    "        pre_1_name.append(results[i][0][0][1])\n",
    "        pre_1_prob.append(results[i][0][0][2])\n",
    "        pre_2_nas.append(results[i][0][1][0])\n",
    "        pre_2_name.append(results[i][0][1][1])\n",
    "        pre_2_prob.append(results[i][0][1][2])\n",
    "        pre_3_nas.append(results[i][0][2][0])\n",
    "        pre_3_name.append(results[i][0][2][1])\n",
    "        pre_3_prob.append(results[i][0][2][2])\n",
    "        pre_4_nas.append(results[i][0][3][0])\n",
    "        pre_4_name.append(results[i][0][3][1])\n",
    "        pre_4_prob.append(results[i][0][3][2])\n",
    "        pre_5_nas.append(results[i][0][4][0])\n",
    "        pre_5_name.append(results[i][0][4][1])\n",
    "        pre_5_prob.append(results[i][0][4][2])     \n",
    "    df = pd.DataFrame({\"Filename\": name_list, \"Result#1_efficient\": pre_1_nas, \"Result#1_Name\": pre_1_name, \"Result#1_Probability\":pre_1_prob, \"Result#2_efficient\": pre_2_nas, \"Result#2_Name\": pre_2_name, \"Result#2_Probability\":pre_2_prob, \"Result#3_efficient\": pre_3_nas, \"Result#3_Name\": pre_3_name, \"Result#3_Probability\":pre_3_prob, \"Result#4_efficient\": pre_4_nas, \"Result#4_Name\": pre_4_name, \"Result#4_Probability\":pre_4_prob, \"Result#5_efficient\": pre_5_nas, \"Result#5_Name\": pre_5_name, \"Result#5_Probability\":pre_5_prob})\n",
    "    return df\n",
    "\n",
    "#exports the DataFrame as a csv-file\n",
    "def exporter(df, path_to_new_csv):\n",
    "    df.to_csv(path_or_buf = path_to_new_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EfficientNetB0(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "names, results = main(r\"C:\\Users\\guest\\OneDrive - Higher Education Commission\\ilmenau study\\2nd semester\\IVP\\project\\data_set_resiezd\")\n",
    "data_f = write_df(name_list=names, results=results)\n",
    "exporter(df=data_f, path_to_new_csv=\"Results_efficientnet.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputest",
   "language": "python",
   "name": "gputest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
